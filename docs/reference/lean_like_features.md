{{ nav_links() }}

Enhancing Backtest Execution Accuracy: Lean Features & QMTL Integration
Introduction
Improving the realism of backtest trade execution requires modeling various market mechanics. QuantConnect’s Lean engine provides a rich set of “reality modeling” features that enhance fill accuracy, including diverse order types/policies, slippage and fee models, liquidity constraints, proper timing of fills, and robust position tracking. QMTL – a DAG-based strategy execution framework – currently focuses on signal generation and lacks these detailed execution simulations. This report analyzes how Lean implements each key feature and proposes a design to transplant similar functionality into QMTL. Where possible, we suggest purely DAG-based solutions; if a direct DAG integration is impractical, we outline hybrid approaches (e.g. an external order-matching layer or portfolio state machine) and explain their pros and cons. The goal is to incorporate the following features into QMTL’s architecture to yield more realistic backtest outcomes:
Order Fill Policies – Support for different order types (market, limit, stop, IOC, FOK, etc.) and their fill rules.
Slippage Modeling – Simulation of price slippage (spread-based, volume-impact, time-delay models, etc.).
Commission (Fee) Models – Configurable trade fees (per broker specifications, percentage or absolute).
Liquidity Constraints – Limits on fills based on volume (per bar or tick) and handling of unfillable orders.
Fill Timing – Controlling when orders execute (end-of-bar vs. intra-bar tick resolution).
Position Tracking State Machine – Maintaining position state (entry, holding, exit) and order lifecycle.
High-Resolution Data Handling – Differentiating tick/quote vs. OHLC bar data and using appropriate prices (bid/ask vs. last) for fills.
Each section below summarizes Lean’s approach and then discusses QMTL integration: feasibility within the DAG model and, if needed, alternative designs (hybrid layers or external modules) to achieve the functionality. We also note how an external execution simulator could hook into QMTL’s workflow if certain features cannot be cleanly implemented as DAG nodes.
1. Order Fill Policies (Market, Limit, IOC, FOK, etc.)
Lean’s Implementation: Lean supports a wide range of order types and time-in-force policies. Order objects in Lean carry a Type (Market, Limit, StopMarket, StopLimit, MarketOnClose, etc.) and an optional TimeInForce specification (Good-Til-Canceled by default, with options like Day, Good-Til-Date, Immediate-Or-Cancel, Fill-Or-Kill). Lean’s backtesting engine uses a pluggable Fill Model to simulate execution for each order type. In the default FillModel.Fill() method, Lean dispatches to specific fill logic based on the order type – for example, MarketFill() for market orders, LimitFill() for limit orders, StopMarketFill() for stops, etc.[1]. This design cleanly separates the handling of different policies. TimeInForce rules are enforced by checking order expiration or fill validity before finalizing the order event – e.g. an IOC order is canceled if not immediately (partially) filled, and a FOK order is canceled if it cannot be completely filled at once. Lean’s engine thus natively understands IOC/FOK semantics. (For instance, in live brokers like Interactive Brokers, Lean maps the IOC/FOK flags to the brokerage API; in backtesting, Lean will simulate the same behavior.) The end result is that Lean can produce realistic outcomes for advanced order types – an IOC limit might fill partially and cancel the remainder, whereas a FOK would either fill entirely (if enough volume/price available in one shot) or not at all. Lean’s flexibility comes from this modular order model design: new order types or policies can be added by extending the fill model or TimeInForce classes[2].
QMTL Design Proposal: To support similar order policies, QMTL needs to introduce an order abstraction and an execution mechanism to handle order logic. In a pure DAG approach, we can define an Order Node/Signal that encapsulates order details (entry signal, order type, limit/stop prices, etc.), and an Execution Node that consumes these order signals along with market data to produce fill events. For example, a strategy’s signal node could output something like {"type": "Limit", "side": "Buy", "quantity": 100, "limit_price": 50.0} when a buy signal is generated. An execution node (downstream in the DAG) would take this and the latest price feed as inputs to simulate what happens next. This execution node’s compute function can implement logic analogous to Lean’s fill model: if type == Market, fill at current price; if Limit, check if market price has reached the limit; if Stop, wait for trigger price; etc. We would also include handling for IOC/FOK: for IOC, the execution node would attempt an immediate fill (using available price/volume data) and mark any unfilled portion as canceled in the same time step (since IOC does not remain working). For FOK, the node would check if full execution is possible (e.g. price touched and sufficient volume available in one tick/bar); if not, it outputs a cancellation event with zero filled quantity. Essentially, the execution node acts as a fill policy simulator within the DAG.
Feasibility in DAG: Implementing basic market/limit/stop orders is feasible by combining the signal and price streams in a node. QMTL’s DAG supports multiple upstreams and time windows, so the execution node can look at recent price data (e.g. current bar’s OHLC or tick) to decide fills. However, modeling IOC/FOK strictly may be challenging if the DAG processes one time step at a time – the execution node would need to determine “immediate” fill based on the same time step’s data. In a bar-resolution backtest, that could mean using the current bar’s prices/volume to decide a fill or cancellation for IOC/FOK. This is doable (e.g. if the bar’s volume or price range is insufficient, mark the IOC/FOK order canceled immediately). It requires the execution node to output not only fill events but also cancellation events for unfilled orders with the same timestamp.
State & Order persistence: One complexity is that limit and stop orders may remain open across multiple time steps until conditions are met. In a DAG (which is acyclic and generally stateless per node execution), it’s non-trivial to carry an order forward. A stateful approach is needed. One solution is to give the Execution Node internal memory: it can maintain a list of pending orders in its function closure or object state. When a new order signal arrives, the node adds it to the pending list. On each compute call (triggered by each new market data update), the node iterates through pending orders and checks fill conditions. Filled orders generate fill outputs and are removed from pending; canceled or expired orders are removed with a cancellation output; others remain pending for the next tick/bar. This essentially implements an order state machine inside the node, allowing partial fills and waiting behavior. While this violates the purely functional ideal of DAG nodes, QMTL nodes are Python objects that could hold state between calls (for example, a closure variable or class attribute). Care must be taken with concurrency (likely the node would run single-threaded sequentially for each new data event, which is acceptable in a backtest sequence). This approach can handle IOC/FOK as well: an IOC order would be added and immediately evaluated on the same tick – if partially fillable, record that partial fill and then cancel the rest in the same iteration (so it won’t carry over); a FOK order would be evaluated and if not 100% fillable at once, canceled immediately.
Alternative Hybrid Approach: If implementing the full order matching logic within a DAG node proves too convoluted or limits reuse, QMTL could introduce a separate Order Execution Engine outside the DAG. In this design, the DAG would output raw order signals (e.g. to a queue or list), and an external simulator (part of QMTL’s backtest runner loop) would consume those signals sequentially, apply fill rules, and then feed the results (fills or position updates) back. This essentially acts like Lean’s Transaction Handler or a “broker emulator.” The pros of an external module are clarity and flexibility: it can naturally handle waiting, partial fills, and time-in-force by advancing through each time step in a loop, much like a real broker processing orders. It could easily maintain order state (since it’s imperative code) and could even simulate a matching engine or order book if needed. The cons are that it breaks the self-contained DAG paradigm – the strategy can’t be entirely expressed as a DAG because execution is happening off to the side. It also introduces complexity in integration: after each DAG update, the runner must call the execution engine, then perhaps inject the results back into the DAG (for example, to a portfolio node or to record trades). There’s also a performance consideration: QMTL’s DAG Manager is optimized to parallelize and reuse node computations, whereas an external loop might become a serial bottleneck (though trade simulation is usually fast compared to indicator calculations).
Integration into QMTL flow: Whether inside a DAG node or via an external module, the order fill simulation should tie into QMTL’s existing execution flow. In practice, we can modify the Runner: after the data stream node updates and signals are computed, we invoke the fill logic. If using an Execution Node in DAG, the Runner simply lets that node execute as part of the graph (the node will produce fill events as data outputs). If using an external order handler, the Runner would collect orders from strategy nodes at each timestep, call the handler to process those orders with the current market data (available via the data nodes), and then output the results. The outputs (fill confirmations, trade price, volume filled, etc.) could be recorded via QMTL’s EventRecorder (persisting trade events to the database) or could be fed into a downstream “portfolio update” node if we design one. One could even envisage a PortfolioState Node that takes fill events and updates positions (see section 6), thereby linking the external engine back into the DAG. This hybrid insertion means the DAG handles data & signals, then the external engine handles execution, and returns data back into the DAG for anything that depends on portfolio state. The key is to ensure this cycle doesn’t violate DAG acyclicity – likely by treating the external step as end-of-cycle side effects or by structuring the strategy such that no further computation in the same timestep depends on the just-executed trades (which is usually true, since trades impact next timestep’s positions).
In summary, QMTL can mimic Lean’s order fill policies by introducing order objects and a fill simulation stage. A stateful execution node in the DAG is one design to achieve this within the DAG framework, though it complicates the pure functional model. Alternatively, an external order-matching layer (with a well-defined interface to the DAG) might offer a cleaner implementation of complex policies like IOC/FOK and partial fills. The choice may depend on QMTL’s tolerance for stateful nodes versus architectural complexity. If maintaining a strict DAG is paramount, a carefully managed stateful node (or set of nodes) can be used to handle order fills within the DAG execution model. If flexibility and realism are the priority, implementing a mini “broker emulator” outside the DAG, while managing data flow to/from it, could be justified – we will see this theme recur with features like liquidity and position tracking below.
2. Slippage Modeling (Spread, Volume, Time-based)
Lean’s Implementation: Lean provides slippage models to simulate the price impact of trades. By default, Lean uses a NullSlippageModel (no slippage) – i.e. orders fill at the exact market price with no additional spread cost[3]. However, Lean includes built-in models to add realism. The simplest is ConstantSlippageModel, which applies a fixed percentage slippage to every fill price (e.g. 0.1% slippage means a buy order pays 0.1% above the market price)[4]. More advanced is the Volume Share Slippage Model, which models slippage as a function of the order size relative to market volume[5][6]. This model uses the formula from Kissell & Glantz: slippage (in % of price) = priceImpactConstant × (OrderVolume / BarVolume)^2, capped by a volumeLimit (maximum fraction of the bar’s volume one order can fill)[7][8]. The idea is that larger orders relative to the available liquidity cause exponentially higher price impact. If the security’s data subscription is a TradeBar, Lean uses that bar’s volume; if it’s a QuoteBar (bid/ask sizes), it uses those as volume; and for assets like Forex or Crypto that often report no volume, the model returns zero slippage (since volume-based impact can’t be calculated)[6]. Lean also introduced a Market Impact Slippage Model, which is a sophisticated model considering execution time, volatility, and permanent vs. temporary impact (based on academic models)[9][10]. This model essentially simulates how prices move during the execution of a large order and includes randomness (“noise”) to mimic real market impact[11][12]. In implementation, each Security in Lean has an ISlippageModel attached (default Null). During order fills, after determining the theoretical fill price, Lean calls asset.SlippageModel.GetSlippageApproximation(...) and adjusts the fill price up or down by that amount[13][14]. For example, a buy order’s fill price is increased by the slippage amount (and a sell’s fill price decreased)[15]. This ensures slippage directly affects the execution price in backtests.
QMTL Integration: QMTL currently doesn’t simulate slippage (orders are effectively filled at market price in the simplistic strategies). We propose introducing a Slippage Model concept in QMTL’s execution process, similar to Lean. The slippage logic can be incorporated whether we use an execution node or an external engine:
Within a DAG Execution Node: The execution node, after determining a raw fill price (e.g. the last traded price or midpoint), can adjust that price to simulate slippage. This node could have configurable parameters or even pluggable model functions. For instance, one could configure a constant slippage percentage for all trades or a volume-impact function. QMTL’s price data (from a StreamInput) typically includes volume and possibly spread information, which the slippage formula can utilize. If our price payload has fields like close and volume, we can implement a volume share model: slippage_pct = k * (order_qty / bar_volume)^2 (bounded by a max percent). The node would then compute slippage_amount = slippage_pct * current_price. If it’s a buy, increase the fill price; if a sell, decrease it – just as Lean does[14]. For assets without volume data (e.g. some crypto/forex feeds), the model can default to zero slippage or use a spread-based slippage (see below). We can also offer a simple constant model for users who just want to assume, say, 0.5% slippage on every trade. Since QMTL is Python-based, these models could be implemented as simple functions or lambdas passed into the execution node’s config, making it flexible (e.g. a user could plug in a custom function of order size, price, volatility, etc.).
Spread-based slippage: A common form of slippage, especially in FX or crypto, is the bid-ask spread. If QMTL can access bid and ask prices (through quote data), we might treat the spread as a form of immediate slippage – e.g. a market buy fills at the ask which is a bit higher than last trade price. Lean indirectly addresses this by suggesting to use QuoteBar subscriptions (so your “price” already includes bid/ask). In QMTL, if such data is available, the execution logic can simply take the appropriate side: fill buys at the ask price and sells at the bid price, instead of the mid or last price. That effectively models spread cost. If only trade prices are available, an alternative is to configure a fixed spread (e.g. for each asset, assume 0.2% spread) and treat half of it as slippage on each side. This could be rolled into the slippage model calculation.
Time-based slippage: If needed, we could simulate that longer order execution times (e.g. trying to execute over several bars) incur more slippage (as Lean’s market impact model does by considering execution time). For QMTL’s initial implementation, this might be overkill, but an example design could be: if an order remains partially filled over N bars, you gradually increase the slippage per fill, or incorporate volatility over that period into the price impact. This is an advanced feature and might rely on an external engine tracking execution duration.
Implementing slippage in QMTL is relatively straightforward once we have an order execution pipeline: it’s essentially a post-processing step on the fill price. The key requirement is that QMTL’s data or models provide the inputs needed (volume, or at least some notion of liquidity). In backtests with daily/minute bars, using bar volume is acceptable. For higher realism, if tick data is available, volume per trade (or order book depth, if known) could drive a more granular slippage – but integrating order book depth is beyond current scope. A volume-based approximation is a good start.
From an architecture standpoint, slippage does not force a change in DAG structure; it’s an internal calculation. If using the external order handler approach, that handler would similarly apply slippage formulas to any fills it generates. For consistency, we might allow the user to specify the slippage model at strategy configuration. For example, QMTL could have a default of “no slippage” (to mimic current behavior), but the user can enable a “VolumeShareSlippage(k=0.1, volume_limit=0.5)” or “ConstantSlippage(0.001)” etc. The selected model would be applied to all orders in the backtest. This parallels Lean’s design where each Security has a slippage model (the user can do security.SetSlippageModel(...) to override)[16][17].
One consideration: if QMTL’s strategy DAG runs many nodes in parallel, we must ensure slippage modeling has access to the needed data at the right time. In a single execution node, that node already has price info. If we split responsibilities (e.g. a separate node computes slippage), it would complicate matters, so it’s best kept within the execution step. The pros of this approach are accuracy and flexibility – users can calibrate slippage to match asset liquidity. The cons (minor) are requiring volume data and making the backtest fills less deterministic (especially if random noise is added as in the market impact model). However, determinism can be maintained by using fixed formulas or a fixed random seed for any noise (Lean’s market impact model allows a random seed input[12]).
In summary, QMTL can and should incorporate slippage to avoid overly optimistic fills. Lean’s approach of modular slippage models can be mirrored by allowing the execution logic to plug in different slippage calculations. Initially, supporting a Null model (0 slippage), a constant percent model, and a volume-impact model would cover most needs. This will enable more realistic backtests, e.g. strategies trading large fractions of daily volume will see their performance adjusted downward due to slippage costs, as they would in reality.
(Lean Example: by default Lean uses no slippage, assuming a fluid high-volume market[18], but users can enable models that increase fill price for large orders. We aim to provide the same capability in QMTL.)
3. Commission and Fee Models
Lean’s Implementation: Realistic backtesting must account for transaction costs. Lean models this with pluggable Fee Models. Each Security in Lean has an IFeeModel that computes the order fee. Lean provides many concrete implementations: e.g. InteractiveBrokersFeeModel, BinanceFeeModel, GDAXFeeModel, PercentageFeeModel, etc., each reflecting a broker’s fee structure or a generic scheme. For example, Interactive Brokers equity fees are modeled at $0.005 per share with a $1 minimum (with adjustments for liquidity add/remove), while crypto exchanges might use a percentage of trade value. Lean’s default for most securities is a Constant $1 fee (some asset classes default differently; for example, futures have per-contract fees). The fee calculation is done when an order is filled: the fill event (OrderEvent) includes an OrderFee object. Lean’s FeeModel interface returns an OrderFee which contains an amount and currency[19]. Lean then deducts this from the portfolio’s cash balance. However, an important detail from Lean’s documentation: in backtesting, the fee model’s output is used for reporting, but Lean’s internal cash bookkeeping might use a separate mechanism (in live trading, actual broker fees are applied to cash book)[20][21]. Regardless, for backtest accuracy, the fee model’s effect is that every trade incurs the specified cost. Lean allows users to override the fee model per security: for instance, one can call security.SetFeeModel(new ConstantFeeModel(5.0)) to apply a $5 fee on that security’s trades[20]. In short, Lean’s structure cleanly separates fee calculation into its own module, parallel to slippage. Many default models are provided and users can create custom ones by subclassing FeeModel (or implementing IFeeModel). This modular approach means the rest of the engine just requests the fee from the model when needed, and applies it.
QMTL Integration: We should equip QMTL with a similar Commission model mechanism. The commission can be implemented in a straightforward way: whenever an order is filled in the simulation, calculate the fee and subtract it from the portfolio (or record it as part of the trade’s P&L). Concretely:
We define a Fee Model interface in QMTL (this could simply be a function or a small class with a method get_fee(order, fill) that returns a fee amount). We can offer a few built-in models: e.g. PercentageFeeModel(x%) for brokers that charge a percentage of trade value, PerUnitFeeModel (fee per share or contract), or FixedFeeModel ($X per trade). For stocks, a common structure is a per-share fee with a minimum; for crypto, a percentage of notional; for futures, maybe a fixed fee per contract. QMTL could also allow specifying fees in terms of basis points. The user could choose one model globally for the backtest or per asset if needed.
The chosen fee model would be applied in the execution process. If using an Execution Node, after determining the fill price and quantity, the node can call something like fee = fee_model(order, fill_price, fill_qty). This fee (a number) would then be output as part of the fill event (e.g. in a structure {"filled_price": X, "filled_qty": Y, "fee": Z}) and also used to update portfolio cash. If using an external engine, similarly, that engine would compute and attach fees for each fill. Essentially, the commission is an attribute of the trade event.
Portfolio impact: In a realistic simulation, fees reduce your cash. So QMTL needs to reflect that in the portfolio tracking (section 6). The design could be that the portfolio state (equity) node or external portfolio object subtracts fees from cash immediately when trades occur. This is straightforward once that state tracking exists. Initially, we can simply log the fees along with trades and ensure they are accounted for in final performance calculations (like net P&L).
Implementing fee models does not pose structural challenges – it’s a small addition to the execution logic. The main effort is to allow configurability. We can make the fee model a property of the strategy or of each StreamInput (if different assets need different fees). For example, if QMTL’s Strategy class could have an attribute commission_model which could be set to a global model or a dict per symbol. During backtest initialization, one could set strategy.fee_model = PercentageFeeModel(0.1%) or assign a custom function. The Execution Node or order handler would have access to this via closure or context.
One must also consider edge cases: zero-fee trading (many crypto exchanges for certain trades, or commission-free brokers) should be representable (the default could be no fee, matching current behavior). Also, if an order is partially filled over multiple ticks, you might charge the commission either per partial fill or once for the whole order. In real markets, commissions are typically per order execution (so if an order fills in multiple parts, some brokers charge per fill, others per order – Lean’s backtest likely counts each fill event separately). We can simplify by charging on each fill event, which is consistent with Lean’s model (each OrderEvent has its own OrderFee).
Another nuance: bid/ask spread vs commission – spread is not a commission but effectively a cost. We handled spread under slippage. Commission is an explicit cost. QMTL should not double-count those, but treat them separately.
In summary, we recommend QMTL adopt a pluggable fee model system akin to Lean. For example, setting a broker-specific model can mimic reality (Lean’s library of fee models can guide us – e.g. IB’s tiered commission, or a simple fixed fee). At minimum, providing a constant fee and a percentage fee option will let users calibrate their backtests. Technically, this is low-hanging fruit: once an order’s fill is determined, applying a formula fee = f(fill_price * quantity) or similar is trivial. The impact on the DAG is minimal – it could be part of the execution computation or a quick separate node that tags fees onto events. We prefer doing it within the execution step to keep all trade details in one place.
By incorporating commission costs, QMTL backtests will avoid overestimating returns for high-turnover strategies. Many strategies that look great gross can be unprofitable after realistic fees, so this feature is essential. Lean’s experience shows the value: they include multiple fee models to cover different markets, and we should aim for similar flexibility. Users could also plug in their own via QMTL’s Python interface (just as Lean users can subclass FeeModel). This keeps QMTL extensible for any future or custom broker fee structures.
4. Liquidity Constraints and Partial Fills
Lean’s Implementation: In reality, not every order can be filled in full – especially large orders can be limited by market liquidity. Lean’s default backtest behavior assumes a fluid, high-volume market[18] – meaning any order up to the bar’s volume gets filled completely at the modeled price. Lean does not explicitly simulate order book depth by default; instead, it implicitly assumes if the price traded to or through your level, you got your whole order filled (this is an optimistic assumption unless volume is unlimited). However, Lean provides tools to introduce liquidity constraints. The primary one is the VolumeShareSlippageModel discussed earlier, which indirectly addresses liquidity by scaling slippage up for large orders. It also has a parameter volumeLimit (default 0.025, i.e. 2.5%) that effectively means: in one bar, the model will only allow you to consume up to 2.5% of that bar’s volume without extreme price impact[8]. If you try to trade more, the slippage grows significantly, which in effect models that you cannot get the rest of the order filled at the same price – you’d move the price. In Lean, this doesn’t leave the order partially open; rather, it fills the order but at a much worse price (thus reflecting impact cost). Lean generally does not carry partial orders across bars in backtests (except perhaps for limit orders that didn’t trigger yet). It assumes either you’re filled or you’re not on a given bar, based on price movement. That said, Lean’s algorithm framework has an Execution scheduling feature (like VWAP or standard trade size scaling) where a user can break a large order into smaller chunks over time, explicitly. But if the user doesn’t do that, Lean will fill the order fully (with slippage) on the first bar that allows it. There is no concept of “unfilled remainder” in Lean’s default backtest for market orders – the order either executes (possibly with slippage) or fails (e.g. limit never hit). In live trading mode, Lean does handle partial fills from broker (updating remaining quantity), so the engine supports the notion of partial fills in order objects (with fields like QuantityFilled, QuantityRemaining). In backtest, partial fills can occur in the sense of limit orders being partially filled if price just touches the level and volume might be insufficient – but the specifics depend on the model in use. Lean doesn’t explicitly simulate volume-by-volume matching unless using tick data. If tick-by-tick data is used, each tick can fill a portion of an order and an order can indeed span multiple ticks until complete or until end of day. Lean’s FillModel and TransactionHandler would then generate multiple OrderEvents (one per tick fill). For example, a large limit order in a tick simulation might get 100 shares filled on one tick, then 300 on the next, etc., until done or canceled. This behavior isn’t documented in the high-level guides but would emerge from how Lean iterates through ticks and leaves the order open with remaining quantity. In summary, Lean’s approach to liquidity in backtests is simplified: it either assumes high liquidity (fill everything) or uses slippage as a proxy for limited liquidity, rather than explicitly leaving part of the order unfilled across bars (except for untriggered limits). There is no built-in concept of an order failing to execute due to volume, except via price not moving enough or slippage making it impractical.
QMTL Integration: To improve realism, QMTL should incorporate liquidity constraints, meaning the simulation should recognize when an order is too large to fully execute at the prevailing price/volume. There are a couple of ways to do this:
Volume-Based Partial Fills: We can use the data’s volume field to decide how many shares/contracts can be filled in the current time step. For example, if a minute bar has volume of 10,000 and our strategy tries to buy 20,000, we might decide that at most 10,000 could be filled in that minute. The remaining 10,000 would either spill over to the next bar or be left unfilled. How to handle the remainder depends on order type and time-in-force. If it’s a Market order (IOC = no, meaning it can work until filled), we could carry the remainder to the next bar as a still-pending market order (which in reality is not how markets work – a market order would sweep the order book immediately, incurring slippage; but if we’re capping per-bar volume to simulate not trading more than available, then effectively you are breaking it up). Alternatively, one could interpret that as you did buy 20,000 but the price would have moved dramatically – which should have been accounted via slippage. There’s a bit of a modeling choice: either we simulate the effect as price impact (slippage) or as partial execution with remainder waiting. Perhaps a combination is best: use volume limits to cap how much fills, and if an order exceeds it, either (a) apply huge slippage to fill it fully (Lean’s approach), or (b) fill only the cap and keep the rest pending. The latter introduces the notion of partial fills over time explicitly.
If we choose to allow partial fills across time, QMTL’s execution node (or external engine) needs to maintain order state (as discussed in section 1). It must track quantity_remaining. For a Market order, carrying it across multiple bars is somewhat artificial (since a true market order wouldn’t sit unfilled), but one could say we are simulating an algorithmic execution (like you only got part done in one interval and will attempt the rest next interval). For Limit orders, carrying remaining quantity is very natural: if only some volume traded at your limit price, you’re partially filled and the rest stays until price moves again or order expires. QMTL should definitely handle partial fills for limit/stop orders – e.g. a large limit buy at $100 could get X shares when price first hits $100, but if not enough sellers, you get filled on X and then if price hovers at $100 for several ticks, you might get more, etc., until your full quantity or price moves away.
Design in DAG: The stateful Execution Node approach already handles this: it can keep track of remaining size for each pending order and gradually reduce it as fills occur. For each time step, it can compute the max fillable quantity. If using bar data, a simple rule might be: fill_qty = min(order_remaining, volume * fill_ratio), where fill_ratio could be an assumption of how much of the bar’s volume you can take. You might default to 100% of volume (meaning you could theoretically take the entire bar’s volume – but if you do, perhaps you should also move the price dramatically; that loops back to slippage). A more conservative default might be some fraction like 50% of bar volume (assuming you can’t consume all trades without pushing price). This is exactly what Lean’s volumeLimit parameter embodies[22]. For example, volumeLimit = 0.5 means you fill at most 50% of the bar’s volume; if your order is bigger, the remainder is effectively pushed to later (Lean instead increases slippage which indirectly limits effective fill). In QMTL, we could explicitly limit fills. We might even expose a parameter for this. The advantage of explicit partial fills: you can then simulate the order taking multiple bars to complete, which might affect the strategy (e.g. your position increases gradually, and if something changes in between, maybe you cancel the rest – though that gets complex).
Order Failure Scenarios: In some cases, an order might not fill at all – e.g. no trades occurred (volume = 0 in that interval), or price never reached your limit. QMTL should handle these cleanly: if volume = 0 and it’s a market order, realistically in a live market a market order would still trade by walking the book (causing price jump). But in a backtest, volume=0 might indicate a closed market or extremely illiquid asset. It might be better to defer the fill to when volume appears rather than assume infinite slippage. So QMTL could simply not fill if volume=0 (i.e. order remains pending). Similarly, if a limit order price isn’t met (e.g. trying to buy at 100 but the bar’s low was 102), Lean would not fill it. QMTL does the same: leave it open to future bars or until expiry. This is straightforward since the execution node can check price conditions each step.
IOC and FOK with liquidity: An IOC order in a low-liquidity context should fill whatever is available immediately and cancel the rest. QMTL’s execution logic can implement that: on the first time step, calculate partial fill (if any) and then cancel the remaining quantity (do not carry it forward). A Fill-Or-Kill should check if the entire quantity is available now; if not, fill nothing and cancel the order. So IOC/FOK become special cases of the partial fill logic combined with time-in-force rules. This again reinforces that maintaining state and time-in-force in the execution simulation is necessary.
Hybrid Approach considerations: If using an external engine, partial fill and liquidity are easier to simulate: you can literally simulate trade by trade. For instance, if you had tick data with individual trade sizes, the external simulator could iterate through ticks until the order quantity is exhausted or the market closes. That’s a very realistic simulation (essentially replaying the limit order book if you have detailed data). If only aggregate bar data is available, the external simulator could subdivide the bar volume into chunks (maybe assume uniform distribution of trades) and “fill” the order in increments. While this level of detail might be unnecessary, it highlights that an external loop can do iterative filling inherently, whereas in a DAG node we often deal with one update per bar. We could simulate iterative filling within a single bar in code, but lacking actual tick data, it would be guesswork (we might assume e.g. constant trading throughout the interval).
Recommendation: Use a simpler approach initially: apply a volume-based cap per interval to decide fills, and allow carrying of remainder if order is GTC. This means QMTL must keep track of not only pending orders but also how much of each is filled so far. We already planned for that in the stateful execution node.
Implementing liquidity constraints will significantly improve backtest realism for strategies that trade large sizes. It prevents the unrealistic scenario of selling 1,000,000 shares in one second when the market only trades 100,000 that second. Instead, in QMTL the strategy might sell 100k with immediate slippage and then still have 900k to go, which either continues next tick or remains pending. The downside to modeling partial fills is that it complicates the strategy feedback: if your strategy logic needs to know if an order fully executed or not, we’d need to communicate that (Lean handles this via order status events). In QMTL, we can similarly provide feedback – e.g. the execution node outputs fill events which include status (Filled, PartiallyFilled, Canceled, etc.). The strategy could query that via an EventRecorder or another node if needed. Even if the strategy doesn’t react intra-trade, it’s important for final accounting.
In summary, QMTL should incorporate a fill quantity calculation based on available liquidity each period. We can follow Lean’s philosophy by defaulting to a high liquidity assumption but giving users the knobs to turn. For example, by default maybe we assume you can fill the entire order (like Lean does), but if the user enables a “volume limit” setting (analogous to Lean’s volumeLimit 2.5%), then the engine will enforce partial fills. Implementing this in the execution node is feasible: it has access to bar_volume from the price stream and order_size. It can compute something like: max_fill = volumeLimit * bar_volume (if volumeLimit=1.0 means you could take 100% of volume; 0.25 means 25%, etc.). Then fill_amount = min(order_remaining, max_fill). If fill_amount < order_remaining, then not everything filled – handle according to IOC/FOK or keep pending. We would also likely increase slippage if you’re consuming a large fraction of volume (which ties into section 2’s models). In a way, volume-based slippage and partial volume fill are two sides of the same coin – one reflects as price change, the other as time delay. QMTL could allow both to be used in tandem for a very conservative simulation or just one of them.
By adopting volume constraints, QMTL can simulate unfilled order scenarios: e.g. if even after some time the order couldn’t fully fill, it remains partially executed. This introduces the need for possibly canceling orders if they overstay (for example, a day order that didn’t fill by end of day would be canceled). Lean’s TimeInForce Day would address that (auto-cancel end of day). QMTL could implement that logic too if needed (e.g. if an order is still open after the session and TIF=Day, cancel it). That might be advanced, but worth mentioning for completeness.
To conclude, adding liquidity constraints in QMTL will involve enhancing the execution simulation to either apply slippage for large orders and/or carry partial fills across intervals. We lean towards implementing explicit partial fills within the execution node’s state machine, as it provides a clearer picture of what’s happening with an order (and allows IOC/FOK behavior to be naturally implemented). This will mirror Lean’s capabilities but potentially even exceed them by allowing multi-bar order execution tracking in backtests. The trade-off is additional complexity in the simulation logic and possibly slightly slower backtest if many orders remain pending. However, for most strategies the number of simultaneous open orders is limited. Proper data structures (like a list of pending orders) will handle this efficiently.
5. Execution Timing (Bar Close vs. Intrabar Tick Fills)
Lean’s Implementation: The timing of when an order is deemed to execute in backtest can significantly affect outcomes. Lean’s behavior depends on the data resolution and order type: - For Market Orders submitted during a bar interval, Lean’s default fill model assumes immediate execution on the same bar’s closing price in backtests[23]. This is a known approximation Lean uses because the engine processes the algorithm at the bar’s end (e.g. OnData at 10:00 receives the 10:00 bar data, and if a market order is placed, Lean fills it at 10:00 bar close price). In reality, you would only get it executed at 10:00:00 plus some latency – effectively the next tick, which could be the next bar’s open if using bar data. Lean acknowledges this discrepancy; it chooses to fill on the same bar to avoid look-ahead to a next bar’s open that isn’t known until that next bar completes (since with only bar data, you can’t see intrabar)[23]. They consider the default “immediate” and note it may not be perfect for illiquid assets, but users are free to override with a custom fill model (e.g. to delay fills)[24].
For Limit/Stop Orders, Lean effectively fills them at the first bar where the price crosses the threshold. If you’re using minute bars, and you place a limit order, Lean checks if the next bars’ high/low penetrated your price. If yes, it fills at a price that is the worst-case within that bar (as discussed earlier: a buy limit is filled at min(limit price, bar.High) to avoid overly favorable pricing)[25][26]. This means the order is considered executed sometime during that bar, but Lean doesn’t specify the exact timestamp – it just assumes by bar close it’s done. If using tick data, Lean would fill at the exact tick when the price condition is met, which is more precise.
Lean also offers specific order types that inherently execute at open or close: MarketOnOpen orders will fill at the next market open price (which in backtest means the next bar’s open if daily, or next session’s open if intraday, etc.), and MarketOnClose orders fill at the market’s close price for that day[27][28]. These are modeled by Lean with their own fill functions that simply take the open/close price accordingly[29][30]. So Lean does allow the user to explicitly say “execute this at tomorrow’s open” via a different order type.
In live trading, Lean of course executes whenever the market order hits the broker; in backtest, the user must be conscious of this bar-close fill approximation. There have been forum discussions (e.g. by Leland in the excerpt) noting that filling on the same bar’s close can be optimistic[31][23]. Lean’s staff suggested that if you want to simulate a more realistic scenario (no execution until next bar’s open), you might use a MarketOnOpen order instead of a Market order submitted at close.
QMTL Integration: QMTL needs to decide how to handle the timing of order execution relative to the data granularity. The ideal is to allow tick-level execution if high-resolution data is available, but also handle bar-level data carefully to avoid look-ahead bias. Several considerations:
If using tick data or very high frequency data: QMTL can emulate real-time order handling closely. For example, if we feed every trade or quote tick into the DAG, then an order triggered by one tick can be filled on a subsequent tick. The execution node would then naturally operate on a tick-by-tick basis. This is the most accurate scenario: e.g. strategy sees price 100 in one tick, sends a buy; maybe the next tick price is 100.05, so that’s the fill price. There’s no ambiguity because we have the next tick.
If using only bar data (e.g. minute bars): We have a choice. The Lean approach (fill on same bar close) is one option – it’s simpler (no delay), but can be too optimistic. A more realistic approach is: if a signal is generated at bar close, then the earliest fill is the next bar’s open (since you couldn’t act until the bar had closed in real time). This avoids using information from the current bar’s close as execution, essentially introducing a one-bar delay for market orders. Some backtesting platforms (like certain settings in Backtrader, Zipline, etc.) enforce next-bar execution to eliminate lookahead bias. The downside is it can make results worse (which is arguably correct) and can complicate comparisons (Lean users sometimes prefer the immediate fill for simplicity). We should allow QMTL users to choose, or at least document the behavior.
Proposal for QMTL: Implement configurable execution timing:
A default mode might mimic Lean: fill market orders on the same bar (assuming the strategy logic executes at bar end, which QMTL currently does since it samples at interval boundaries).
An alternative mode (“realistic mode”) would delay execution to the next tick or bar. We could implement this by having the execution node not produce a fill event until a new data point arrives after the order signal. Mechanically, if an order comes in at time T (end of bar), the execution node could store it and only output the fill when it processes time T+Δ (next bar). This is doable in the stateful node approach: e.g. mark orders with a small “not yet executed” status, and check on the next tick.
To illustrate: Suppose we have minute data. At 10:00 bar close, strategy outputs a buy signal. The Execution Node receives this at timestamp 10:00. In immediate mode, it will use 10:00’s close price to fill right then. In delayed mode, the node could instead hold this order and not fill it at 10:00. When the 10:01 bar data comes in, the node then fills the order at 10:01’s open price (or the first tick in that minute). This aligns with how a trader would place a market order after seeing 10:00 close – it executes at 10:01 open. Implementing this logic means the node must know the difference between current bar and next bar context. One simple way: when an order is received, tag it with “waiting for next price.” The next time the node is called with new price data, if an order is tagged waiting, execute it. There may be edge cases (e.g. if market is closed, next price could be next day’s open – the node would need to detect session boundaries, possibly via no data overnight).
Stop/Limit orders: If using bar data, these inherently execute intrabar in simulation once conditions met. Lean’s method essentially assumes they trigger and fill within the bar of crossing. If we want to avoid any lookahead, one could require the price to go through the level and fill at next bar’s open beyond the level – but that’s arguably overly strict. It might be acceptable to mirror Lean’s approach for limits/stops: if today’s high hit your buy limit, you got filled (because you could have had that order resting from prior bars or even the same bar start). The timing issue mostly concerns market orders that are generated in response to the current bar. So the biggest bias is with market orders executed immediately on the bar that generated them. To combat that, delaying to next bar is advisable.
Tick vs Bar mixing: QMTL might allow a strategy to subscribe to both bars and ticks (for example, use daily bars for strategy logic but also have intraday tick data for execution). If so, the execution node could operate on tick data even if signals are bar-based. For instance, strategy signals a trade on a daily bar; the execution node then plays it out on the subsequent intraday ticks to simulate a realistic fill. This is a powerful hybrid approach and arguably the best practice: use coarser data for decision, finer data for execution simulation. Lean supports this to some extent (you could add a secondary subscription of higher resolution just for fill modeling). QMTL’s DAG being multi-interval (as described in the architecture doc, section 3.1)[32] can handle multiple upstream intervals. So we could feed, say, a 1-minute price stream and also a tick stream into the execution node. The node can then use the tick stream to fill orders in between bar updates. For example, if a daily strategy places an order at day close, the execution node might wait for the next day’s intraday ticks (or opening auction tick) to fill. This would drastically improve realism but requires the availability of such data and the complexity of managing multi-rate data in DAG. QMTL’s NodeCache model is built for multi-interval alignment, but we must carefully design how the execution node consumes it (likely using the tick events sequentially until the order is done).
QMTL Runner adjustments: If not doing it within the node, an external approach could also manage timing. For example, an external simulation loop can naturally fill at next bar because it would process the strategy at time T, then when incrementing time to T+1, execute the order. This is conceptually simpler – basically enforce a one-step delay in the run loop for market orders. But if we already implement within the node, that might not be needed.
Given these considerations, a practical plan is: - Implement the execution node to by default fill on the same bar (for consistency with Lean defaults). But make it configurable (maybe a parameter like delay_market_fill=True to shift to next bar). - If high-resolution data is present (e.g. tick feed), always use it naturally (no artificial delay needed, since the next tick will come moments later anyway). If only bars are present and delay_market_fill is enabled, do the next-bar logic as described. - Document clearly to users which mode is being used. Possibly even allow both in one backtest to compare.
The pros of introducing next-bar execution: eliminates lookahead bias and is more conservative (which users who want robust strategies will prefer). The cons: it can lower strategy returns and might confuse users if they expect Lean-like behavior. Perhaps offering both modes is the best solution.
From a technical standpoint, implementing a delay is not hard with the stateful design. We just have to ensure an order doesn’t inadvertently fill with no price (if no next bar exists – e.g. end of backtest, then it would remain unfilled which is fine).
One more subtlety: Bar timestamp alignment. QMTL uses epoch timestamps; if we treat an order at time T, and next bar is T+interval, that’s straightforward for constant intervals. For daily, next bar might be next trading day (skip weekends). The execution node or runner must be aware of trading calendar to some extent. Lean handles this in MarketOnOpen by scheduling to the next market session. QMTL might not have a built-in calendar concept yet. We might approximate that if there is a gap in data timestamps, that implies break (weekend or holiday). A MarketOnOpen would fill at the next available data point. That’s a detail but worth noting.
To illustrate QMTL’s execution timing, consider an example: Strategy uses 1-hour bars. At 3:00 PM bar, it generates a buy. With immediate mode, QMTL would fill at ~3:00 PM price. With delayed mode, QMTL would fill at 4:00 PM bar open price (assuming market open continuous; if not, next morning open). Lean by default would fill at 3:00 bar close, which is slightly optimistic. The difference could be significant if there’s a jump at 4:00. By providing delayed mode, QMTL allows capturing that jump as slippage.
In summary, QMTL should incorporate the concept of fill timing: - Provide MarketOnOpen/Close order types or properties so that users can explicitly schedule those (this is easy to add once order types exist – just treat them specially in execution: hold until next session open or use that bar’s close). - Allow normal market orders to either fill immediately or next tick depending on configuration. - Ensure limit/stop orders are processed each tick/bar as data arrives (no special delay needed since they’re usually resting orders). - Use the highest resolution data available for fill decisions. If multiple data streams are present, execution node can operate on the finest granularity to decide the exact fill time and price.
By doing this, QMTL can simulate strategies that are sensitive to execution timing (like close-to-close vs intraday signals). It also avoids inadvertent lookahead biases. This design essentially aligns QMTL with best practices in backtesting: one should not assume you can trade on information of the bar that signaled the trade unless explicitly modeling an order type that does so (like MOC orders).
(Lean Example: Lean fills backtest trades at the close of the current bar by default, treating them as immediate[23]. This can be adjusted with different order types or custom models. QMTL’s flexible DAG could surpass Lean by naturally handling intrabar ticks and scheduling execution on the next available price update instead of the same bar.)
6. Position Tracking and State Management
Lean’s Implementation: Lean maintains portfolio state through its Security Holdings and Portfolio objects. Each asset (Security) has a SecurityHolding which tracks quantities, average cost, unrealized P&L, etc., and the overall Portfolio aggregates these. When orders are filled, Lean immediately updates the holding: for example, if you bought 100 shares, the SecurityHolding for that symbol now has Quantity = 100 and AveragePrice = fill price (weighted by existing holdings if any). Lean’s design is event-driven – an OrderEvent is produced for each fill, and the TransactionHandler updates the Portfolio accordingly. There is an implicit state machine for position status: essentially the quantity sign (positive long, negative short, or zero flat) and maybe an internal flag if we consider entering vs. exiting. However, Lean doesn’t expose a formal finite-state-machine for a position; it’s just derived from quantity and order history. For instance, going from 0 to +100 shares means a new long position was entered; going from +100 to 0 means the long was closed (exited); going from +100 to +200 is an increase, etc. The Lean API allows user code to check Portfolio[symbol].Invested (a boolean if quantity != 0) or examine holding quantity to see if they are in a position.
Lean also manages order states (Submitted, PartiallyFilled, Filled, Canceled, etc.) in the Order objects. A limit order could be partially filled, remain open, then later fully filled or canceled – Lean tracks that and generates multiple events. This is a state machine for order lifecycle more than for the position itself, but the two are related.
In Lean’s typical algorithm, the user doesn’t manually manage the position state machine; they issue orders and rely on Lean to maintain the portfolio. However, under the hood Lean’s code must ensure consistency (no double counting, proper average cost updates, etc.). Lean’s event model effectively ensures that at any time, the portfolio state reflects all prior fills.
QMTL Integration: QMTL will need to implement position tracking so that strategies can be aware of and respond to their current holdings, and so that performance can be calculated. There are two parts: 1. Tracking open positions (quantities, average price, market value). 2. Order state management (knowing if an order is open, partially filled, etc.).
The question specifically mentions a “position state machine (entry, holding, exit)”. This suggests possibly modeling the discrete states of a position’s lifecycle. For example: - Flat (no position), - Entering (an entry order has been placed but not fully filled yet), - Long or Short (position held), - Exiting (an exit order placed but not fully out yet).
While Lean doesn’t explicitly model these named states, we could incorporate such a concept in QMTL to help strategy logic or risk management. However, even if we don’t formalize those labels, we must at least maintain the raw data: position size and whether an order is pending.
Proposed Implementation Approaches:
Within DAG (Position Node): We can create a Portfolio/Position Node in the DAG that has the role of consuming trade events (from the execution node) and outputting current position information. This node would effectively accumulate the fills over time. It could output at each time step something like: {"position": qty, "avg_price": p, "unrealized_PnL": x} for each asset. Downstream strategy nodes (if needed) could take this into account (e.g. you might have a node that checks if you’re already in a position to avoid double-entry). However, introducing a feedback from positions to strategy can create a cycle in the DAG if not handled carefully (because strategy decisions influence positions and vice versa). In a pure DAG, you cannot have a loop. But often strategies do need to know if they have a position (for example, “if not invested, then enter on signal, else if already in, maybe ignore new signal or exit”). How to handle this? One method is to treat the position info as just another data stream node that the strategy can read. But connecting it directly would form a cycle (position node depends on execution which depends on strategy’s order signal). We might break the cycle by introducing a one-step lag deliberately: essentially, the strategy can only react to position changes on the next time step. This is akin to how in event-driven systems you can’t immediately respond to your own action in the same instant. This may be acceptable: e.g. if you place an order now, you know you’ll be in position next tick if filled. Many strategies simply keep an internal flag for invested or not and update it when orders fill; we can mirror that with a slight delay.
Alternatively, the strategy could maintain some internal state flag “I am in a trade” without requiring a DAG feedback. This is possible because QMTL’s nodes can have internal memory. For example, a signal node could incorporate logic “only emit a buy signal if not already in trade” by maintaining a boolean that it sets when it emits a buy and resets when an exit happens. The exit could be detected either by another input or some callback. This is complex to do purely in DAG, so it hints that an external state might be simpler.
External State Machine: Another approach is to handle positions entirely outside the DAG in the order execution layer. If we adopt the external “broker emulator” idea, that component naturally tracks positions as it fills orders (just like Lean’s TransactionHandler updates the portfolio). We could then expose this position info to the user at the end or through logging, but how would the strategy get it? If the strategy’s logic needs to use current holdings (e.g. position sizing adjustments, or not doubling up), you have to feed it back. This could be done by injecting an artificial data node that represents position state and is updated by the external engine. But injecting data from outside into the DAG could violate assumptions unless done carefully (maybe via the Gateway/TagQuery mechanism or by treating it as a stream with an external provider that the external engine writes to).
Hybrid: A compromise might be to manage the portfolio outside but also mirror minimal needed info inside. For instance, maintain the official P&L and positions in the external simulator (for reporting and accuracy), but let the strategy node itself maintain an “isInvested” flag in a simplified way. This requires user’s strategy code to handle it, which is not ideal because we want the system to handle it generally.
Given QMTL’s aim to incorporate these features into its flow, a clearer design is to formalize an internal portfolio object: - We can create a QMTL service (similar to how the DAG manager works) that keeps the state of each strategy’s positions. This service updates on order fills and can be queried. - From the DAG perspective, we might not feed that back into the computation graph for now (to avoid complexity), unless explicitly needed. Many simple strategies can be written without needing to query portfolio state (they just know when they send an order and assume it goes through). But more advanced ones do need it (like to avoid overlapping positions or to compute position-based metrics).
If we do want to integrate it, one safe approach is to restrict it to non-cyclic usage: for example, allow a node to output position state for logging or final analysis, but not necessarily feed into the decision nodes (or if it does, enforce that decisions use the previous step’s state). This could perhaps be done by offsetting the position node’s output by one time index. There is an analogy: in time-series modeling, sometimes you include previous state as input to next state calculation, forming a feedback loop that is unrolled over time – this can be represented in a DAG if you consider each time step as separate nodes or by using delay elements. QMTL might not have an explicit notion of time-step loops, but maybe we could hack it by using the period in NodeCache. For instance, a position node could keep the last known position (period=1 history) and a strategy node could peek at that from one index behind. This is intricate, but possibly doable with careful use of the CacheView.track_access or similar. However, such complexity might be beyond current QMTL scope.
Perhaps the simplest route: - Implement portfolio tracking for correctness (so that we can compute metrics like total returns including open P&L). - Expose minimal signals to the strategy to prevent obvious errors (like an option to not allow concurrent long and short, etc., or an automatic cancellation if trying to buy when already at max position). - Otherwise, leave advanced position-dependent strategy logic to either user-managed state or future enhancements.
State Machine Concept: The prompt hints at using a state machine design possibly outside the DAG. They even mention “external portfolio state machine introduction” as a possible solution if DAG integration is hard. Using a formal FSM (finite state machine) could help clearly define transitions: e.g. - Flat -> Entered (when an entry order fully fills, transition to Holding state), - Holding -> Exit (when an exit order triggers, possibly an intermediate “exiting” until filled), - etc. This could be implemented with a library or custom code. The benefit is easier reasoning and visualization (one could even log state changes or draw diagrams for strategy flow).
However, implementing an FSM might be overkill unless the strategy logic is particularly complex about entry/exit conditions. Many trading strategies can be sufficiently described with a simple flag or position count.
QMTL Implementation specifics: - We should maintain a record of current position (for each asset the strategy trades). This includes quantity and average cost. We update it on fills. - We also track cash balance if doing full portfolio simulation (initial capital minus cost of buys plus proceeds of sells minus fees, etc.). Lean does this in Portfolio.CashBook. QMTL should as well if we want to compute metrics like return on capital. - We need to log trades (entry price, exit price, profit) for analysis. QMTL’s EventRecorder can log every fill event in a database table, which is great for later analysis of trades. - The strategy or user should be able to query performance results after the backtest (like total return, max drawdown). These come from accurate position tracking and price data.
So as a deliverable design, perhaps we say: - Create an internal PortfolioManager (either as part of Runner or a special node) that receives order fill events and maintains positions. - For each fill, update the position for that symbol: new quantity = old quantity + fill_quantity (with sign depending on buy/sell), compute new average price if entering or increasing, or realized P&L if reducing a position. Also update cash (Cash -= fill_quantity * fill_price for buys minus fees, etc.). - If a position goes to zero, calculate the P&L for that round trip (entry vs exit) if needed for stats. - Provide outputs: e.g. at the end, produce a summary of trades or P&L.
Integration into DAG flow: If we treat this PortfolioManager as part of the external loop, it doesn’t affect the DAG except that it consumes events. However, they asked to describe how to insert it into QMTL’s flow. Possibly: - After execution events are determined each step, the Runner invokes PortfolioManager to update state. - Optionally, one could feed the updated state back into the DAG on the next iteration. For example, one could imagine a special StreamInput that provides current portfolio data at each timestamp. But that might double-count time steps if not careful.
Given time, it might be acceptable initially that strategy nodes don’t directly get portfolio info; instead, the user can infer or incorporate that via their own state if needed. The primary importance is that the backtest results and trade events are correct.
Pros of internal DAG approach: Could allow strategy to do things like “if position is open, skip new signal” in a declarative way. Cons: possible DAG cycles or complexity.
Pros of external approach: Simpler and aligns with how backtest engines usually work (separation of strategy logic and portfolio accounting). Cons: harder for strategy to use position data in real-time decisions, unless we implement a feedback channel.
One intermediate approach is to allow the strategy to query some global state in its compute function (not purely functional, but a pragmatic escape hatch). For example, in the strategy’s Node compute_fn, one could call something like portfolio = get_current_portfolio() which the Runner provides (since the Runner knows the portfolio between steps). This breaks strict functional purity but could be engineered as a well-defined side-channel. This is similar to how one might check a global context for current holdings. This should be used carefully (to avoid time-traveling), but if the portfolio is updated after orders, the next call to strategy’s compute_fn could access the latest state. This would effectively allow intra-DAG feedback without formal DAG edges, by using a global object. While not the cleanest pattern, it’s an option if needed and could be hidden behind an API.
To wrap up, we propose: - Implement a robust Portfolio/Position tracking module in QMTL that updates on order fills. - Use it to calculate P&L and ensure no double counting (so execution of overlapping orders updates the same position). - Provide the user with end-of-backtest performance metrics and possibly a trade log. - Where strategy logic requires knowledge of current position, either encourage using internal state in the strategy node (like remembering you sent an order and treating that as position) or in the future allow reading from the portfolio state (through a safe mechanism).
With that in place, QMTL will be able to accurately simulate the progression of positions from entry to exit, including partial holdings if orders partially fill. This answers the “state machine” aspect: the combination of order management (open vs filled) and portfolio state (flat vs invested) essentially forms the state machine for each asset. We can even formalize it by printing state transitions: e.g. when quantity goes from 0 to >0, that’s an Entry state; >0 constant is Holding; >0 back to 0 is Exit completed, etc. This is more for analysis/documentation, but it might help debugging strategies.
(Lean Example: Lean’s Portfolio keeps track of invested positions per symbol[33], updating immediately on fills. QMTL can achieve the same by maintaining internal position records and perhaps using a state-machine approach to track transitions like entry/exit.)
7. High-Resolution Data Handling (Ticks, Quotes, Trade Bars)
Lean’s Implementation: Lean supports multiple data resolutions and types. It distinguishes TradeBars (OHLCV bars typically for equities, etc.), QuoteBars (bid/ask OHLC for assets like FX or crypto), and Ticks (individual trade or quote updates). Lean’s fill logic adapts based on what data is available: - If using TradeBars (no explicit bid/ask), Lean’s fill model often assumes the last trade price as the execution price for market orders[13]. Slippage or spread must be added via models since the bar’s price is a single value. - If using QuoteBars or Tick quotes, Lean can fill using the actual bid or ask. For example, in Lean, Forex data is typically quote-based. A market buy in Forex will fill at the ask price from the quote tick. Lean’s SlippageModel also notes that for QuoteBars, “barVolume” is interpreted as bid size or ask size[34], implying it knows the difference. - Lean allows algorithms to request tick-level resolution. In backtest, if tick data is present, the engine will iterate through every tick event. This means orders can fill at intra-bar times. Lean’s TimeSlice and Scheduling ensures that if you subscribe to tick data, your OnData is called per tick. So a market order placed on one tick could be filled potentially on the very next tick (or even the same tick if synchronous, but likely next since it processes events sequentially). - Lean does not unify trade and quote ticks automatically; the user must subscribe to what they need. For equities, tick data includes trade ticks (with trade price and size) and quote ticks (bid/ask updates). Lean’s fill model for equities using tick data will typically use trade ticks for execution (assuming you hit the trades), but if one wanted to be precise, they might use the quotes to decide fill price (bid/ask). - The engine is aware of data type: e.g. for crypto, if volume is not provided, Lean’s default slippage returns 0 (because it can’t compute volume fraction)[6]. Also, Lean will simply treat the last price as both bid and ask if no separate quotes exist (or some models might set a fixed spread).
QMTL Integration: QMTL should gracefully handle different data granularities and ensure the execution simulation uses the appropriate fields: - Tick data support: QMTL’s architecture appears to allow any interval, including very small ones. While it might not explicitly have a concept of “tick” (since interval has to be a number in seconds), we could treat tick data as an asynchronous stream of events. Possibly one can set interval=None or use a special node that pushes events as they come. If not, one might approximate tick data by using the smallest time delta as interval (e.g. 1 second or 1 millisecond). The NodeCache 4D model uses floor(timestamp/interval) for indexing[35], which suggests truly irregular timestamps might be awkward. However, if tick timestamps are milliseconds, using interval=1 (second) could bunch ticks by second, which isn’t truly tick-level. But QMTL might handle them sequentially regardless. This is a technical nuance: QMTL might need some enhancement to fully support irregular timing without aggregation (perhaps treat each tick as a separate event in the queue with its exact timestamp).
For our design, we assume we can feed tick data in sequence. The Execution Node, if it has tick resolution input, will naturally process each tick. This means the simulation can step through fine-grained data for order matching. So if realistic execution is desired, the user could supply tick data to QMTL (or at least second-by-second trades). QMTL’s engine should then schedule the DAG updates at each tick.
Quote vs Trade prices: To simulate realistic fills, we want to use bid/ask for market orders if available. For example, if QMTL has an order to buy and we have a Quote tick with Bid=100, Ask=101, LastTrade=100.5, the actual fill should happen at Ask ~101 (plus any slippage). If only LastTrade is available, we might fill at LastTrade + some spread estimate. Thus, QMTL’s Execution Node should check if data includes separate bid/ask. In practice, we can design the price stream to carry a structure with fields. For instance, a tick data point might be represented as {"last": 100.5, "bid": 100.0, "ask": 101.0, "bid_size": 500, "ask_size": 300}. Or a QuoteBar might have open/close for bid and ask. If the data source is QuestDB or pandas, these could be columns. The compute function in execution node can access those. For a buy order:
If ask exists, use that as base fill price; for a sell, use bid.
If only last exists, use last but consider adding slippage or a fixed spread.
If only OHLCV bars exist: Lean’s convention is to use the current bar’s close for market orders (with no spread). We might do similarly unless user chooses next bar open method. For limit orders, use high/low as described.
Data resolution mixing: As mentioned, QMTL can mix intervals. We should ensure the Execution Node can accept multiple upstreams of different intervals. According to QMTL docs[32], nodes maintain a window for each upstream and presumably compute when the slowest (or all required) have new data. The execution node could subscribe to both the signal (which might be per minute) and tick data (which could be many per minute). We then have to decide on a triggering logic: ideally, the execution node should recompute on every tick to update order fills. The signal input won’t have new data every tick (only each minute), but the tick input will. QMTL’s model might call the compute_fn whenever any upstream has new data (and provides a view of latest values for each). So each tick, the execution node would see the same last signal (no change) but a new tick price. That’s actually good: it can then continue filling any pending orders using those ticks. We have to be careful that the node’s logic can handle the case “no new orders, but existing order still open and new price arrived -> attempt fill more”.
If the DAG manager doesn’t call the node on every tick unless the signal changed, we might need to adjust. But since they mention multi-upstream windows, likely it does call on any new upstream event. We might have to mark the signal as not requiring a new event for node to run, or ensure node always executes on tick events by not gating on signal. This might require setting execute=True for that node’s mapping in a way that ticks drive it. Possibly QMTL’s scheduling can handle it if configured properly (the TagQuery mechanism might be relevant but assuming local execution, it should be fine).
Performance considerations: Processing tick-by-tick is heavier. But QMTL with Ray parallelism could parallelize other nodes; the execution node itself will run sequentially (since it must simulate sequential fills). This should be acceptable for moderate tick loads, though extremely high-frequency data might be slow in Python. If needed, one could implement critical loops (like matching volume) in numpy or numba, but probably not necessary unless tick counts are in millions.
Data types differences: For assets like Forex with no reported volume, QMTL’s volume-based logic should realize that. If volume is None or zero often, our volume share slippage and partial fill logic might need to adapt. Lean in such cases defaults to no slippage[6], which might be optimistic but without better info it’s common. We might do similar: treat volume as effectively infinite or skip volume-based calcs for FX/crypto unless user supplies an alternate liquidity measure (like order book depth or known average volume). Alternatively, user can set a fixed slippage for those.
Quote vs Trade Bars handling: If the input data is QuoteBars (with separate bid/ask OHLC), QMTL should fill at the appropriate side. E.g. if using minute QuoteBar, and we get an order during that minute: we might fill at that minute’s ask price (somewhere between ask open and ask close, but Lean would likely use ask close if filling at bar close, etc.). Perhaps simpler: if a QuoteBar is provided, we assume mid-bar that ask ~ last trade. Possibly skip the nuance and just use close ask or last. This is a minor detail.
Multiple data streams (like trade ticks and quote ticks): If QMTL had both, which to use? Could be advanced to combine (like ensure fill price is ask and ensure volume comes from trades). But probably out of scope – usually one uses either trade ticks (with their own volume) or quote ticks (with sizes but not actual executed volume). Lean’s mention of QuoteBar volume being bid/ask size suggests they might use those as volume in slippage for FX, which is not actual traded volume but an estimate of liquidity.
For QMTL, we likely won’t delve that deep initially; using trade volume or a notional volume is fine.
Summary of QMTL design adjustments: - Ensure the data pipeline can accommodate tick-level updates. This may involve using a small interval or a special triggering mechanism. - The Execution Node must correctly choose fill prices based on data fields: e.g. prefer ask/bid if present. If not, use last price. - The slippage model should know when not to apply (e.g. if using real bid/ask, maybe slippage should only represent additional impact beyond spread). - Possibly allow the user to specify the type of data (trade vs quote) so the execution logic knows how to interpret it. - Testing on different scenarios (e.g. equity with minute bars vs crypto with tick quotes) will ensure the logic covers all.
By handling high-resolution data properly, QMTL will be able to simulate scenarios such as: - Tick-by-tick scalping strategy: where every tick triggers logic and orders may fill within seconds. - Multi-bar execution: as discussed, splitting an order across many ticks until done. - Accurate spread costs: on instruments where we have bid/ask, no need to guess slippage for spread – we directly use those prices.
This will make QMTL a powerful backtester on par with Lean in terms of data fidelity. Many simpler backtesters only use bars and often ignore spread; by including these details we differentiate QMTL as a more institutional-grade simulator.
(Lean Example: Lean’s slippage model notes that if Quote data is used, the bar volume comes from bid/ask sizes, and if no volume (as in some FX data), slippage defaults to zero[6]. This underscores the importance of handling data differences. QMTL should similarly adjust its fill logic depending on whether it’s using trade prices or bid/ask quotes for realism.)

Conclusion
In this report, we dissected how QuantConnect Lean achieves high-fidelity backtest execution and proposed a blueprint for incorporating those features into QMTL’s DAG-based framework. The key enhancements identified were:
Order Fill Policies: Support for various order types (market, limit, stop) and time-in-force rules (IOC, FOK, GTC). Lean’s fill model architecture can be emulated by introducing an execution component in QMTL that applies different fill logic depending on order attributes[1]. QMTL can implement this either within a stateful execution node or via an external order-matching loop, with the latter offering easier handling of complex policies at the cost of DAG purity.
Slippage Models: Realistic price impact simulation is crucial. Lean uses pluggable slippage models (null, constant, volume-share, market impact) and applies slippage to market order fills[15]. QMTL can mirror this by allowing configurable slippage functions in its execution process, using bar volume and order size to adjust fill prices. This will account for spread and order size effects, preventing overly optimistic fills[17][6].
Commission Fees: Lean’s engine attaches a fee model to each security (with various broker-specific implementations). We plan to give QMTL a similar capability, adding commission calculations for each fill. Whether a simple flat fee or a percentage of trade value, these costs will be deducted from the portfolio cash, aligning backtest P&L with reality. By modularizing fees, users can plug in exchange-specific rules or test different fee scenarios easily.
Liquidity Constraints: To handle cases of limited volume, we will enhance QMTL’s fills to either partially fill orders or incur large slippage when volume is insufficient. Lean assumes a fluid market by default[18] but provides volume-based slippage to model impact[7]. QMTL can take it further by explicitly limiting fill quantity per bar (e.g. using a volumeLimit parameter like Lean’s 2.5% default[22]) and carrying unfilled portions forward as pending orders. This approach, implemented via the order state machine in the execution node, allows simulation of order books and partial executions, bringing the backtest closer to how a real trade might execute over time.
Execution Timing: Recognizing the timing mismatch in bar data, QMTL will offer control over fill timing. Lean’s backtester fills orders on the same bar by default (assuming immediate execution)[23], which can be too optimistic. QMTL can introduce an option to execute orders on the next tick or bar, eliminating lookahead bias. Additionally, by leveraging tick data if available, QMTL will naturally fill orders at the exact moments prices trade, rather than only at bar boundaries. We also plan to support MarketOnOpen and MarketOnClose orders, echoing Lean’s specialized order types for scheduling execution at session boundaries[27][28].
Position Tracking: A robust mechanism to track positions and portfolio value through time will be added. Lean updates portfolio holdings immediately on each fill and provides properties to check investment state. QMTL’s DAG does not inherently track state, so we propose either a dedicated Portfolio node or an external portfolio manager to maintain current positions (quantity, average cost) and cash. This acts as the state machine for trade lifecycle – from flat to long/short and back to flat, with all intermediate order states monitored. By logging order events and updating position state, we ensure QMTL can report realistic performance metrics (realized P&L, unrealized P&L, drawdowns, etc.) and enforce rules like no overlapping opposite positions (unless shorting is allowed). If a purely DAG solution is too limiting for immediate strategy feedback, we may incorporate a slight hybrid approach (e.g. allow strategy nodes to query last known position via a side-channel) to avoid DAG loops while still enabling position-aware decisions.
High-Resolution Data & Spread: QMTL will fully utilize whatever data resolution is provided. If tick-level trades or quotes are available, the execution simulation will operate on each event, yielding highly granular fills. We will properly handle quote data: for instance, filling buy orders at the ask price and sells at the bid price when those are known, rather than using mid or last. This ensures spread costs are reflected inherently (Lean achieves this by encouraging the use of QuoteBars for assets like FX, where backtest fill = ask for buys)[6]. In absence of explicit quotes, we rely on slippage models to approximate the spread. QMTL’s architecture already supports multi-interval DAG inputs[32], so mixing a lower-frequency strategy with a high-frequency execution feed is feasible and recommended for realism. We will leverage that to implement, for example, a minute-bar strategy that executes on second-by-second data.
Pros and Cons of DAG vs External Augmentation: Throughout the design, we evaluated doing these enhancements inside the DAG graph versus in an external layer. Keeping everything in the DAG (via specialized nodes) maintains architectural consistency and allows distributed computation reuse. It means the entire strategy (signals + execution) can be represented as one connected DAG. However, certain behaviors (like iterative order fills and stateful feedback) are not naturally expressed in a purely acyclic, stateless graph. Introducing stateful nodes (as we did with the execution node holding pending orders) breaks the functional paradigm slightly but is a pragmatic solution. Using an external execution engine (a loop outside the DAG) is conceptually simpler for partial fills and portfolio updates – it essentially turns QMTL into a more traditional event-driven backtester at that stage. The downside is integration complexity and potentially losing out on DAG features for that part (like deduplication or parallelism). We have charted a middle path: push as much as possible into the DAG nodes (for speed and reuse), but be open to a contained external helper if needed (especially for portfolio accounting or any logic that inherently requires sequential progression).
For example, we might implement the portfolio state updates externally after each time step (since that doesn’t need to feed back into the DAG immediately). This would avoid creating a cycle while still keeping the strategy’s signal generation purely DAG-based. On the other hand, order matching and slippage we attempted to keep inside the DAG via the Execution node.
Each feature’s integration was analyzed with this balance in mind. In cases where DAG modeling becomes too contorted (like feeding position info back into strategy), a recommendation was made to handle it in the runner or via slight abstraction (like giving the strategy a method to check position that actually reads from a cached external state). These are acceptable compromises to achieve the end goal: a realistic execution simulation in QMTL that rivals Lean’s, without abandoning QMTL’s core DAG execution model.
By implementing the above features, QMTL will greatly improve backtest realism. Strategies will no longer assume every order fills at the close price with infinite liquidity and zero cost; instead, they will face simulated challenges akin to live trading: spreads, slippage on large orders, limited volume, and the nuances of order timing. Lean’s architecture and solutions provided a roadmap – from fill models to slippage/fee plugins and portfolio tracking – and we have tailored those ideas to QMTL’s distributed DAG system. In cases of difficulty, we proposed hybrid solutions (e.g. an external order handler or portfolio state machine) and discussed their pros/cons and insertion points in QMTL’s flow.
In conclusion, the enhanced QMTL design will consist of: - A list of execution realism features (order types, slippage, fees, liquidity rules, timing options, position state) akin to Lean’s reality modeling. - A corresponding implementation plan for each, detailing whether it’s done via new DAG nodes, internal state additions, or an external module, and how it interfaces with QMTL’s existing components (Gateway, DAG Manager, Runner).
This approach keeps QMTL’s high-level strategy definition and DAG execution benefits, while adding a lower layer (within or just alongside the DAG) that handles the gritty details of trade execution simulation. The result will be a more accurate, Lean-like backtesting engine built into QMTL, enabling users to trust that their DAG-modeled strategies will behave in backtest much closer to how they would in real markets – accounting for the many microstructure effects that were previously neglected.
Sources:
QuantConnect Lean Engine repository and documentation, for reference implementations of fill models, slippage, fees, and brokerage models[1][13][17][6]. Lean’s forum discussions on backtest fill assumptions and improvements provided insight into handling bar-close vs. intraday order execution[23].
QMTL documentation and code, to understand the DAG architecture and ensure our designs align with its data flow model[32]. This ensured that multi-interval data and stateful behavior can be integrated without breaking QMTL’s core principles.

[1] [13] [14] [15] [18] [25] [26] [27] [28] [29] [30] FillModel.cs
https://github.com/QuantConnect/Lean/blob/93d58d5cdfac666f2d5207ba1901b2c221729249/Common/Orders/Fills/FillModel.cs
[2] TimeInForce.cs
https://github.com/QuantConnect/Lean/blob/93d58d5cdfac666f2d5207ba1901b2c221729249/Common/Orders/TimeInForce.cs
[3] [4] [5] [6] [7] [8] [9] [10] [11] [12] [16] [17] [22] [34] Supported Models - QuantConnect.com
https://www.quantconnect.com/docs/v2/writing-algorithms/reality-modeling/slippage/supported-models
[19] FeeModel.cs
https://github.com/QuantConnect/Lean/blob/93d58d5cdfac666f2d5207ba1901b2c221729249/Common/Orders/Fees/FeeModel.cs
[20] [21] [33] How to make Set SlippageModel and FeeModel work? - QuantConnect.com
https://www.quantconnect.com/forum/discussion/17157/how-to-make-set-slippagemodel-and-feemodel-work/
[23] [24] [31] Market Order Backtesting Behavior - QuantConnect.com
https://www.quantconnect.com/forum/discussion/10369/market-order-backtesting-behavior/
[32] [35] [architecture.md](../architecture/architecture.md)

{{ nav_links() }}


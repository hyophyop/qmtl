# Basic Alertmanager and Prometheus rules for QMTL metrics
# For a complete list of suggested alerts see docs/operations/monitoring.md
alertmanager:
  route:
    receiver: 'slack'
  receivers:
    - name: 'slack'
      slack_configs:
        - channel: '#alerts'
          send_resolved: true

prometheus:
  groups:
    - name: qmtl
      rules:
        - alert: DiffDurationHigh
          expr: diff_duration_ms_p95 > 200
          for: 5m
          labels:
            severity: warning
          annotations:
            summary: Diff processing slow
        - alert: DiffFailureRateHigh
          expr: sum(rate(diff_failures_total[5m])) / clamp_min(sum(rate(diff_requests_total[5m])), 1e-6) > 0.05
          for: 5m
          labels:
            severity: warning
          annotations:
            summary: DAG diff failure rate above 5%
        - alert: DiffThroughputLow
          expr: sum(rate(diff_requests_total[5m])) < 0.01
          for: 10m
          labels:
            severity: warning
          annotations:
            summary: DAG diff throughput below 0.6/min
        - alert: NodeCacheMemoryHigh
          expr: nodecache_resident_bytes{node_id="all",scope="total"} > 5e9
          for: 5m
          labels:
            severity: warning
          annotations:
            summary: NodeCache memory usage high
        - alert: QueueLagHigh
          expr: queue_lag_seconds > queue_lag_threshold_seconds
          for: 5m
          labels:
            severity: warning
          annotations:
            summary: Kafka consumer lag above threshold
        - alert: ComputeNodeCountHigh
          expr: compute_nodes_total > 50000
          for: 10m
          labels:
            severity: warning
          annotations:
            summary: ComputeNode count growth is abnormal
        - alert: QueueCountHigh
          expr: queues_total > 100000
          for: 10m
          labels:
            severity: warning
          annotations:
            summary: Queue count growth is abnormal
        - alert: SentinelSkewHigh
          expr: sentinel_skew_seconds > 5
          for: 5m
          labels:
            severity: warning
          annotations:
            summary: Sentinel traffic skew persists beyond 5s
        - alert: CrossContextCacheHit
          expr: cross_context_cache_hit_total > 0
          for: 0m
          labels:
            severity: critical
          annotations:
            summary: Cross-context cache hit detected (SLO=0)
            runbook: docs/operations/monitoring.html#runbook-cross-context-cache-hits-slo-0
        - alert: SeamlessSla99thDegraded
          expr: histogram_quantile(0.99, sum by (le) (rate(seamless_sla_deadline_seconds_bucket{phase="total"}[5m]))) > 240
          for: 5m
          labels:
            severity: warning
            service: seamless
          annotations:
            summary: Seamless SLA 99th percentile exceeded 240s for 5 minutes
            runbook: docs/operations/seamless_sla_dashboards.html
        - alert: SeamlessBackfillStuckLease
          expr: min_over_time(backfill_completion_ratio[10m]) < 0.5
          for: 10m
          labels:
            severity: critical
            service: seamless
          annotations:
            summary: Seamless backfill lease stuck below 50% completion
            runbook: docs/operations/seamless_sla_dashboards.html#runbooks
        - alert: SeamlessConformanceFlagSpike
          expr: sum(increase(seamless_conformance_flag_total[15m])) > 50
          for: 15m
          labels:
            severity: warning
            service: seamless
          annotations:
            summary: Surge in Seamless conformance flags over the last 15 minutes
            runbook: docs/operations/seamless_sla_dashboards.html#validation-tooling
